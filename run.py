#!/usr/bin/env python3
"""
run.py - javelin-video-analysis ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ

æ—¢å­˜æ©Ÿèƒ½ã«åŠ ãˆã¦ã€æ–°ã—ã„å¯è¦–åŒ–æ©Ÿèƒ½ã‚’CLIã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§åˆ¶å¾¡ã§ãã‚‹ã€‚
ã™ã¹ã¦ã®æ–°æ©Ÿèƒ½ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆOFFã§å¾Œæ–¹äº’æ›æ€§ã‚’ä¿ã¤ã€‚
"""

import argparse
import os
import sys
import logging
import yaml
import json
from pathlib import Path
from typing import Dict, Any, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))

import cv2
import numpy as np

# æ—¢å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from src.pipelines.pose_analysis import PoseAnalyzer

# æ–°ã—ã„å¯è¦–åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
try:
    from jva_visuals.registry import VisualPipeline, VisualPassRegistry
    from jva_visuals.adapters import adapt_state
    VISUALS_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Visual enhancements not available: {e}")
    VISUALS_AVAILABLE = False

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def load_config(config_path: Optional[str] = None) -> Dict[str, Any]:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    default_config = {
        "height_m": None,
        "visuals": {},
        "output": {"export_landmarks": False},
        "blender": {"enabled": False},
        "debug": {"profile_performance": False}
    }
    
    if config_path and os.path.exists(config_path):
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                file_config = yaml.safe_load(f) or {}
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®šã§æ›´æ–°
            config = {**default_config}
            config.update(file_config)
            
            logger.info(f"Loaded config from: {config_path}")
            return config
        except Exception as e:
            logger.error(f"Failed to load config file {config_path}: {e}")
    
    return default_config


def override_config_with_args(config: Dict[str, Any], args: argparse.Namespace) -> Dict[str, Any]:
    """CLIã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§è¨­å®šã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰"""
    
    # èº«é•·è¨­å®š
    if args.height_m:
        config["height_m"] = args.height_m
    
    # å¯è¦–åŒ–è¨­å®š
    visuals = config.get("visuals", {})
    
    if args.vectors:
        visuals["vectors"] = True
    if args.heatmap:
        visuals["heatmap"] = True
    if args.hud:
        visuals["hud"] = True
    if args.wrist_trail:
        visuals["wrist_trail"] = True
    if args.glow_trail:
        visuals["glow_trail"] = True
    
    # å‡ºåŠ›è¨­å®š
    output = config.get("output", {})
    if args.export_landmarks:
        output["export_landmarks"] = True
        output["landmarks_filename"] = args.export_landmarks
    
    # Blenderè¨­å®š
    blender = config.get("blender", {})
    if args.blender_overlay:
        blender["enabled"] = True
        blender["render_overlay"] = True
    
    config["visuals"] = visuals
    config["output"] = output
    config["blender"] = blender
    
    return config


def export_landmarks_json(landmarks_data: list, output_path: str):
    """ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’JSONå½¢å¼ã§å‡ºåŠ›"""
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump({
                "format": "mediapipe_pose_landmarks",
                "version": "1.0",
                "frame_count": len(landmarks_data),
                "landmarks": landmarks_data
            }, f, indent=2)
        
        logger.info(f"Exported landmarks to: {output_path}")
    except Exception as e:
        logger.error(f"Failed to export landmarks: {e}")


def print_blender_commands(video_path: str, landmarks_path: str, output_path: str):
    """Blenderå®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ã‚’è¡¨ç¤º"""
    blender_script = project_root / "blender_bridge" / "scripts" / "setup_scene.py"
    
    commands = [
        "# Blenderé€£æºã‚³ãƒãƒ³ãƒ‰ä¾‹:",
        f"blender --background --python {blender_script} -- \\",
        f"  --video {video_path} \\",
        f"  --landmarks {landmarks_path} \\", 
        f"  --output {output_path}",
        "",
        "# ã¾ãŸã¯æ—¢å­˜ã®Blenderãƒ•ã‚¡ã‚¤ãƒ«ã«é©ç”¨:",
        f"blender your_scene.blend --python {blender_script} -- \\",
        f"  --video {video_path} \\",
        f"  --landmarks {landmarks_path} \\",
        f"  --output {output_path}"
    ]
    
    print("\n" + "\n".join(commands) + "\n")


def process_video_all_variants(input_path: str, base_output_path: str, config: Dict[str, Any]) -> bool:
    """4ã¤ã®å¯è¦–åŒ–ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åŒæ™‚å‡ºåŠ›"""
    logger.info("ğŸ¬ 4ã¤ã®å¯è¦–åŒ–ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åŒæ™‚å‡ºåŠ›ã—ã¾ã™...")
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
    base_name = Path(base_output_path).stem
    output_dir = Path(base_output_path).parent
    
    variants = [
        {
            "name": "éª¨æ ¼+è»Œè·¡",
            "filename": f"{base_name}_skeleton_with_trail.mp4",
            "config_override": {
                "visuals": {
                    "trails": {"enabled": True, "right_wrist": True},
                    "vectors": {"enabled": False},
                    "heatmap": {"enabled": False},
                    "hud": {"enabled": False}
                }
            }
        },
        {
            "name": "ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—",
            "filename": f"{base_name}_heatmap.mp4",
            "config_override": {
                "visuals": {
                    "heatmap": {"enabled": True, "show_colorbar": True},
                    "vectors": {"enabled": False},
                    "trails": {"enabled": False},
                    "hud": {"enabled": False}
                }
            }
        },
        {
            "name": "ã‚²ãƒ¼ãƒ é¢¨HUD",
            "filename": f"{base_name}_gaming_hud.mp4",
            "config_override": {
                "visuals": {
                    "hud": {"enabled": True, "show_metrics": True},
                    "vectors": {"enabled": False},
                    "heatmap": {"enabled": False},
                    "trails": {"enabled": False}
                }
            }
        },
        {
            "name": "Blenderé€£æºç”¨",
            "filename": f"{base_name}_for_blender.mp4",
            "config_override": {
                "visuals": {
                    "vectors": {"enabled": True},
                    "heatmap": {"enabled": True},
                    "trails": {"enabled": True, "right_wrist": True},
                    "hud": {"enabled": False}
                },
                "output": {"export_landmarks": True}
            }
        }
    ]
    
    success_count = 0
    total_variants = len(variants)
    
    for i, variant in enumerate(variants, 1):
        print(f"\nğŸ“Š [{i}/{total_variants}] {variant['name']}ã‚’å‡¦ç†ä¸­...")
        
        # è¨­å®šã‚’ä¸Šæ›¸ã
        variant_config = config.copy()
        variant_config.update(variant["config_override"])
        
        # å‡ºåŠ›ãƒ‘ã‚¹
        output_path = output_dir / variant["filename"]
        
        # Blenderé€£æºç”¨ã®å ´åˆã¯ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚‚å‡ºåŠ›
        if variant["name"] == "Blenderé€£æºç”¨":
            landmarks_path = output_dir / f"{base_name}_landmarks.json"
            variant_config["output"]["landmarks_filename"] = str(landmarks_path)
        
        # å‡¦ç†å®Ÿè¡Œ
        if process_video(input_path, str(output_path), variant_config):
            success_count += 1
            logger.info(f"âœ… {variant['name']}: {output_path}")
        else:
            logger.error(f"âŒ {variant['name']}ã®å‡¦ç†ã«å¤±æ•—")
    
    # Blenderé€£æºã‚³ãƒãƒ³ãƒ‰ã®è¡¨ç¤º
    if success_count >= 3:  # Blenderé€£æºç”¨ã‚‚æˆåŠŸã—ã¦ã„ã‚‹å ´åˆ
        blender_video = output_dir / f"{base_name}_for_blender.mp4"
        landmarks_file = output_dir / f"{base_name}_landmarks.json"
        blender_output = output_dir / f"{base_name}_3d_overlay.mp4"
        
        print(f"\nğŸ­ Blender 3Dé€£æºã‚³ãƒãƒ³ãƒ‰:")
        print(f"blender --background --python blender_bridge/scripts/setup_scene.py -- \\")
        print(f"  --video {blender_video} \\")
        print(f"  --landmarks {landmarks_file} \\")
        print(f"  --output {blender_output}")
    
    print(f"\nğŸ‰ å®Œäº†: {success_count}/{total_variants} ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å‡ºåŠ›ã—ã¾ã—ãŸ")
    return success_count == total_variants


def process_video(input_path: str, output_path: str, config: Dict[str, Any]) -> bool:
    """å‹•ç”»ã‚’å‡¦ç†"""
    logger.info(f"Processing video: {input_path}")
    
    # å…¥åŠ›ãƒã‚§ãƒƒã‚¯
    if not os.path.exists(input_path):
        logger.error(f"Input video not found: {input_path}")
        return False
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    output_dir = os.path.dirname(output_path)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
    
    # å‹•ç”»ã®èª­ã¿è¾¼ã¿
    cap = cv2.VideoCapture(input_path)
    if not cap.isOpened():
        logger.error(f"Failed to open video: {input_path}")
        return False
    
    # å‹•ç”»ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    if not fps or fps <= 0:
        fps = 30.0
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    logger.info(f"Video: {width}x{height}, {fps} fps, {total_frames} frames")
    
    # å‡ºåŠ›å‹•ç”»ã®è¨­å®š
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    if not out.isOpened():
        logger.error(f"Failed to create output video: {output_path}")
        cap.release()
        return False
    
    # PoseAnalyzerã®åˆæœŸåŒ–
    pose_analyzer = PoseAnalyzer()
    if config.get("height_m"):
        pose_analyzer.set_scale_from_reference(height * 0.8, config["height_m"] * 0.8)
    
    # å¯è¦–åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åˆæœŸåŒ–
    visual_pipeline = None
    if VISUALS_AVAILABLE and config.get("visuals"):
        visual_passes = VisualPassRegistry.build_from_config(
            config["visuals"], fps, config.get("height_m")
        )
        if visual_passes:
            visual_pipeline = VisualPipeline(visual_passes)
            logger.info(f"Initialized {len(visual_passes)} visual passes")
    
    # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ç”¨
    landmarks_data = []
    export_landmarks = config.get("output", {}).get("export_landmarks", False)
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
    frame_count = 0
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            if frame_count % 30 == 0:  # 30ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«é€²æ—è¡¨ç¤º
                progress = (frame_count / total_frames) * 100 if total_frames > 0 else 0
                elapsed_time = (frame_count / fps) if fps > 0 else 0
                logger.info(f"Processing frame {frame_count}/{total_frames} ({progress:.1f}%) - Elapsed: {elapsed_time:.1f}s")
            
            # ãƒãƒ¼ã‚ºè§£æ
            state = pose_analyzer.process(frame, fps)
            
            # åŸºæœ¬ã®éª¨æ ¼æç”»
            result = pose_analyzer.render_basic(frame, state)
            
            # å¯è¦–åŒ–ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’é©ç”¨
            if visual_pipeline:
                try:
                    result = visual_pipeline.apply_all(
                        result, state, fps, config.get("height_m")
                    )
                except Exception as e:
                    logger.error(f"Visual pipeline error at frame {frame_count}: {e}")
            
            # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
            if export_landmarks and state.get("points"):
                frame_landmarks = []
                for i, point in enumerate(state["points"]):
                    if point is not None:
                        frame_landmarks.append({
                            "id": i,
                            "x": float(point[0]) / width,  # æ­£è¦åŒ–åº§æ¨™
                            "y": float(point[1]) / height,
                            "visibility": 1.0
                        })
                    else:
                        frame_landmarks.append({
                            "id": i,
                            "x": 0.0,
                            "y": 0.0,
                            "visibility": 0.0
                        })
                
                landmarks_data.append({
                    "frame": frame_count,
                    "timestamp": frame_count / fps,
                    "landmarks": frame_landmarks
                })
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ å‡ºåŠ›
            out.write(result)
    
    except KeyboardInterrupt:
        logger.info("Processing interrupted by user")
    except Exception as e:
        logger.error(f"Error during processing: {e}")
        return False
    finally:
        cap.release()
        out.release()
        pose_analyzer.close()
    
    # å‡¦ç†å®Œäº†ã®è©³ç´°æƒ…å ±
    processing_time = frame_count / fps if fps > 0 else 0
    logger.info(f"Video processing completed: {output_path}")
    logger.info(f"Processed {frame_count} frames in {processing_time:.2f}s of video content")
    
    # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    if export_landmarks and landmarks_data:
        landmarks_filename = config.get("output", {}).get("landmarks_filename", "landmarks.json")
        # æ—¢ã«ãƒ‘ã‚¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã®ã¾ã¾ä½¿ã†
        if os.path.isabs(landmarks_filename) or os.path.dirname(landmarks_filename):
            landmarks_path = landmarks_filename
        else:
            landmarks_path = os.path.join(output_dir, landmarks_filename) if output_dir else landmarks_filename
        export_landmarks_json(landmarks_data, landmarks_path)
        
        # Blenderã‚³ãƒãƒ³ãƒ‰ã®è¡¨ç¤º
        if config.get("blender", {}).get("enabled", False):
            blender_output = output_path.replace(".mp4", "_blender_overlay.mp4")
            print_blender_commands(output_path, landmarks_path, blender_output)
    
    return True


def main():
    parser = argparse.ArgumentParser(
        description="Javelin Video Analysis with Enhanced Visualizations",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # åŸºæœ¬ã®éª¨æ ¼è¡¨ç¤ºã®ã¿ï¼ˆæ—¢å­˜æ©Ÿèƒ½ã€å¾Œæ–¹äº’æ›ï¼‰
  python run.py --video input.mp4 --output output.mp4

  # ãƒ™ã‚¯ãƒˆãƒ«ã¨ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’è¿½åŠ 
  python run.py --video input.mp4 --output output.mp4 --vectors --heatmap

  # ã™ã¹ã¦ã®å¯è¦–åŒ–æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ– + Blenderé€£æº
  python run.py --video input.mp4 --output output.mp4 --vectors --heatmap --hud --glow-trail \\
                --height-m 1.80 --export-landmarks landmarks.json --blender-overlay

  # ğŸ¬ 4ã¤ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åŒæ™‚å‡ºåŠ›ï¼ˆæ¨å¥¨ï¼ï¼‰
  python run.py --all-variants --height-m 1.80

  # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
  python run.py --video input.mp4 --output output.mp4 --config configs/visuals.yaml
        """
    )
    
    # å…¥å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§input/outputãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½¿ç”¨ï¼‰
    parser.add_argument("--video", help="å…¥åŠ›å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: input/å†…ã®æœ€åˆã®.mp4ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰")
    parser.add_argument("--output", help="å‡ºåŠ›å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: output/analysis_<input_name>.mp4ï¼‰")
    
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
    parser.add_argument("--config", help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆYAMLï¼‰")
    
    # èº«é•·è¨­å®š
    parser.add_argument("--height-m", type=float, help="è¢«å†™ä½“ã®èº«é•·ï¼ˆãƒ¡ãƒ¼ãƒˆãƒ«ï¼‰")
    
    # å¯è¦–åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument("--vectors", action="store_true", help="é€Ÿåº¦ãƒ»åŠ é€Ÿåº¦ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¡¨ç¤º")
    parser.add_argument("--heatmap", action="store_true", help="é€Ÿåº¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’è¡¨ç¤º")  
    parser.add_argument("--hud", action="store_true", help="ã‚²ãƒ¼ãƒ é¢¨HUDã‚’è¡¨ç¤º")
    parser.add_argument("--wrist-trail", action="store_true", help="å³æ‰‹é¦–è»Œè·¡ã‚’è¡¨ç¤º")
    parser.add_argument("--glow-trail", action="store_true", help="å…‰è»Œè·¡ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’è¡¨ç¤º")
    
    # ãƒãƒ«ãƒå‡ºåŠ›ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument("--all-variants", action="store_true", 
                       help="4ã¤ã®å¯è¦–åŒ–ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åŒæ™‚å‡ºåŠ›ï¼ˆéª¨æ ¼+è»Œè·¡ã€ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã€ã‚²ãƒ¼ãƒ é¢¨ã€Blenderé€£æºï¼‰")
    
    # å‡ºåŠ›ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument("--export-landmarks", help="ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’JSONã§å‡ºåŠ›ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŒ‡å®šï¼‰")
    
    # Blenderé€£æº
    parser.add_argument("--blender-overlay", action="store_true", 
                       help="Blenderå®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ã‚’è¡¨ç¤ºï¼ˆè¦ --export-landmarksï¼‰")
    
    # ãƒ‡ãƒãƒƒã‚°
    parser.add_argument("--verbose", action="store_true", help="è©³ç´°ãƒ­ã‚°ã‚’å‡ºåŠ›")
    
    args = parser.parse_args()
    
    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå…¥å‡ºåŠ›ãƒ‘ã‚¹è¨­å®š
    if not args.video:
        # inputãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰æœ€åˆã®.mp4ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        input_dir = Path("input")
        if input_dir.exists():
            video_files = list(input_dir.glob("*.mp4"))
            if video_files:
                args.video = str(video_files[0])
                logger.info(f"è‡ªå‹•é¸æŠã•ã‚ŒãŸå…¥åŠ›å‹•ç”»: {args.video}")
            else:
                logger.error("inputãƒ•ã‚©ãƒ«ãƒ€ã«.mp4ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
        else:
            logger.error("inputãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return False
    
    if not args.output:
        # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
        input_path = Path(args.video)
        output_dir = Path("output")
        output_dir.mkdir(exist_ok=True)  # outputãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
        args.output = str(output_dir / f"analysis_{input_path.name}")
        logger.info(f"è‡ªå‹•è¨­å®šã•ã‚ŒãŸå‡ºåŠ›ãƒ‘ã‚¹: {args.output}")
    
    # è¨­å®šèª­ã¿è¾¼ã¿
    config = load_config(args.config)
    config = override_config_with_args(config, args)
    
    # å¯è¦–åŒ–æ©Ÿèƒ½ã®åˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
    if not VISUALS_AVAILABLE and any([args.vectors, args.heatmap, args.hud, args.wrist_trail, args.glow_trail, args.all_variants]):
        logger.warning("å¯è¦–åŒ–æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚åŸºæœ¬æ©Ÿèƒ½ã®ã¿ã§å®Ÿè¡Œã—ã¾ã™ã€‚")
    
    # å‹•ç”»å‡¦ç†å®Ÿè¡Œ
    if args.all_variants:
        # 4ã¤ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åŒæ™‚å‡ºåŠ›
        success = process_video_all_variants(args.video, args.output, config)
    else:
        # é€šå¸¸ã®å˜ä¸€å‡ºåŠ›
        success = process_video(args.video, args.output, config)
    
    if success:
        if args.all_variants:
            print(f"\nğŸ‰ å…¨ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†å®Œäº†ï¼")
            print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€: {Path(args.output).parent}")
        else:
            print(f"\nâœ… å‡¦ç†å®Œäº†: {args.output}")
            
            # è¨­å®šå†…å®¹ã®è¡¨ç¤º
            enabled_features = []
            visuals = config.get("visuals", {})
            if visuals.get("vectors"): enabled_features.append("ãƒ™ã‚¯ãƒˆãƒ«")
            if visuals.get("heatmap"): enabled_features.append("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
            if visuals.get("hud"): enabled_features.append("HUD")
            if visuals.get("wrist_trail"): enabled_features.append("æ‰‹é¦–è»Œè·¡")
            if visuals.get("glow_trail"): enabled_features.append("å…‰è»Œè·¡")
            
            if enabled_features:
                print(f"ğŸ“Š æœ‰åŠ¹ãªæ©Ÿèƒ½: {', '.join(enabled_features)}")
            else:
                print("ğŸ“Š åŸºæœ¬éª¨æ ¼è¡¨ç¤ºã®ã¿ï¼ˆå¾Œæ–¹äº’æ›ãƒ¢ãƒ¼ãƒ‰ï¼‰")
        
        if config.get("height_m"):
            print(f"ğŸ“ èº«é•·è¨­å®š: {config['height_m']:.2f}m")
        
        sys.exit(0)
    else:
        print("âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        sys.exit(1)


if __name__ == "__main__":
    main()